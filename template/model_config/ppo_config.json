{
    "type": "ppo_agent",

    "update_mode": {
        "unit": "episodes",
        "batch_size": 64,
        "frequency": 20
    },
    "memory": {
        "type": "latest",
        "include_next_states": false,
        "capacity": 20000
    },

    "step_optimizer": {
        "type": "adam",
        "learning_rate": 1e-4
    },
    "subsampling_fraction": 0.1,
    "optimization_steps": 50,

    "discount": 0.97,
    "entropy_regularization": 0.01,
    "gae_lambda": null,
    "likelihood_ratio_clipping": 0.2,

    "baseline_mode": "states",
    "baseline": {
        "type": "mlp",
        "sizes": [32, 32]
    },
    "baseline_optimizer": {
        "type": "multi_step",
        "optimizer": {
            "type": "adam",
            "learning_rate": 1e-4
        },
        "num_steps": 21
    },

    "saver": {
        "directory": null,
        "seconds": 20
    },
    "summarizer": {
        "directory": null,
        "labels": ["rewards"],
        "seconds": 20
    },
    "execution": {
        "type": "single",
        "session_config": null,
        "distributed_spec": null
    }
}